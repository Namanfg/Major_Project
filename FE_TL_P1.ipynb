{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader,Dataset # custom datasets\n",
    "from torchvision import transforms,datasets # mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os \n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all rows\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Display all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Set display width to avoid truncation\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting things setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda present: cuda\n",
      "name: NVIDIA GeForce MX330\n"
     ]
    }
   ],
   "source": [
    "# check for gpu presence\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "name = torch.cuda.get_device_name(device=None)\n",
    "print(f'cuda present: {device}\\nname: {name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the path for the data\n",
    "# BASEDIR = 'C:\\\\Users\\\\naman\\\\Downloads\\\\archive\\\\flickr30k_images'\n",
    "# data_path =  os.path.join(BASEDIR,'flickr30k_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the directory of the trail dataset\n",
    "TEST_DIR = 'C:\\\\Python course\\\\Major\\\\Trail_Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((600,600)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5,0.5,0.5],std=[0.5,0.5,0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name  = []\n",
    "class Image_Data_Generator(Dataset):\n",
    "    def __init__(self,directory,transform=None):\n",
    "        self.directory = directory\n",
    "        self.transform = transform\n",
    "        self.image_files = [f for f in os.listdir(directory) if f.endswith(('.png','.jpg','.jpeg'))]\n",
    "        for f in self.image_files:\n",
    "            f = f[:-4]\n",
    "            if f not in img_name:\n",
    "                img_name.append(f)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        self.image_path = os.path.join(self.directory,self.image_files[idx])\n",
    "        image = Image.open(self.image_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Image_Data_Generator(directory=TEST_DIR,transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataLoader(data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPLY RESNET "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
      "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
      "             ReLU-15          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-16          [-1, 256, 56, 56]               0\n",
      "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
      "             ReLU-19           [-1, 64, 56, 56]               0\n",
      "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
      "             ReLU-22           [-1, 64, 56, 56]               0\n",
      "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
      "             ReLU-25          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-26          [-1, 256, 56, 56]               0\n",
      "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
      "             ReLU-29           [-1, 64, 56, 56]               0\n",
      "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
      "             ReLU-32           [-1, 64, 56, 56]               0\n",
      "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
      "             ReLU-35          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-36          [-1, 256, 56, 56]               0\n",
      "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
      "             ReLU-39          [-1, 128, 56, 56]               0\n",
      "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
      "             ReLU-42          [-1, 128, 28, 28]               0\n",
      "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
      "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-47          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-48          [-1, 512, 28, 28]               0\n",
      "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
      "             ReLU-51          [-1, 128, 28, 28]               0\n",
      "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
      "             ReLU-54          [-1, 128, 28, 28]               0\n",
      "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-57          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-58          [-1, 512, 28, 28]               0\n",
      "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
      "             ReLU-61          [-1, 128, 28, 28]               0\n",
      "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
      "             ReLU-64          [-1, 128, 28, 28]               0\n",
      "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-67          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-68          [-1, 512, 28, 28]               0\n",
      "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
      "             ReLU-71          [-1, 128, 28, 28]               0\n",
      "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
      "             ReLU-74          [-1, 128, 28, 28]               0\n",
      "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-77          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-78          [-1, 512, 28, 28]               0\n",
      "           Conv2d-79          [-1, 256, 28, 28]         131,072\n",
      "      BatchNorm2d-80          [-1, 256, 28, 28]             512\n",
      "             ReLU-81          [-1, 256, 28, 28]               0\n",
      "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
      "             ReLU-84          [-1, 256, 14, 14]               0\n",
      "           Conv2d-85         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n",
      "           Conv2d-87         [-1, 1024, 14, 14]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-89         [-1, 1024, 14, 14]               0\n",
      "       Bottleneck-90         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-91          [-1, 256, 14, 14]         262,144\n",
      "      BatchNorm2d-92          [-1, 256, 14, 14]             512\n",
      "             ReLU-93          [-1, 256, 14, 14]               0\n",
      "           Conv2d-94          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
      "             ReLU-96          [-1, 256, 14, 14]               0\n",
      "           Conv2d-97         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-99         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-100         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-101          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-102          [-1, 256, 14, 14]             512\n",
      "            ReLU-103          [-1, 256, 14, 14]               0\n",
      "          Conv2d-104          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-105          [-1, 256, 14, 14]             512\n",
      "            ReLU-106          [-1, 256, 14, 14]               0\n",
      "          Conv2d-107         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-109         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-110         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-111          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-112          [-1, 256, 14, 14]             512\n",
      "            ReLU-113          [-1, 256, 14, 14]               0\n",
      "          Conv2d-114          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-115          [-1, 256, 14, 14]             512\n",
      "            ReLU-116          [-1, 256, 14, 14]               0\n",
      "          Conv2d-117         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-119         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-120         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-121          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 14, 14]             512\n",
      "            ReLU-123          [-1, 256, 14, 14]               0\n",
      "          Conv2d-124          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
      "            ReLU-126          [-1, 256, 14, 14]               0\n",
      "          Conv2d-127         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-129         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-130         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
      "            ReLU-133          [-1, 256, 14, 14]               0\n",
      "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
      "            ReLU-136          [-1, 256, 14, 14]               0\n",
      "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-139         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-140         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-141          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-142          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-143          [-1, 512, 14, 14]               0\n",
      "          Conv2d-144            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-145            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-146            [-1, 512, 7, 7]               0\n",
      "          Conv2d-147           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096\n",
      "          Conv2d-149           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-151           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-152           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-153            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-154            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-155            [-1, 512, 7, 7]               0\n",
      "          Conv2d-156            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-157            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-158            [-1, 512, 7, 7]               0\n",
      "          Conv2d-159           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-161           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-162           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-163            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-164            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-165            [-1, 512, 7, 7]               0\n",
      "          Conv2d-166            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-167            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-168            [-1, 512, 7, 7]               0\n",
      "          Conv2d-169           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-171           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-172           [-1, 2048, 7, 7]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "================================================================\n",
      "Total params: 23,508,032\n",
      "Trainable params: 23,508,032\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 286.55\n",
      "Params size (MB): 89.68\n",
      "Estimated Total Size (MB): 376.80\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "resnet = models.resnet50(pretrained=True).to(device)\n",
    "resnet = nn.Sequential(*(list(resnet.children())[:-1]))\n",
    "summary(resnet,input_size=(3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.eval()\n",
    "features = []\n",
    "with torch.no_grad():\n",
    "    for images,_ in data:\n",
    "        images = images.to(device)\n",
    "        output = resnet(images)\n",
    "        output = output.view(output.size(0),-1)\n",
    "        features.append(output.cpu())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.1053, 0.9231, 0.3318,  ..., 0.0904, 0.1563, 0.1781],\n",
       "         [0.2849, 0.4690, 0.5033,  ..., 0.1356, 0.2589, 0.3747],\n",
       "         [0.1355, 0.1182, 0.3567,  ..., 0.0315, 0.0560, 0.1500],\n",
       "         ...,\n",
       "         [0.1240, 0.5719, 0.1252,  ..., 0.0340, 0.0432, 0.1434],\n",
       "         [0.1783, 0.5770, 0.3486,  ..., 0.0658, 0.0317, 0.2162],\n",
       "         [0.0741, 0.3467, 0.1679,  ..., 0.0286, 0.0853, 0.0655]])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPLY EFFICIENT NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficient_net = models.efficientnet_b7(pretrained=True).to(device)\n",
    "efficient_net = nn.Sequential(*(list(efficient_net.children()))[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficient_net.eval()\n",
    "features = []\n",
    "with torch.no_grad():\n",
    "    for images,_ in data:\n",
    "        images = images.to(device)\n",
    "        output = output.view(output.size(0),-1)\n",
    "        features.append(output.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1053, 0.9231, 0.3318,  ..., 0.0904, 0.1563, 0.1781],\n",
       "        [0.2849, 0.4690, 0.5033,  ..., 0.1356, 0.2589, 0.3747],\n",
       "        [0.1355, 0.1182, 0.3567,  ..., 0.0315, 0.0560, 0.1500],\n",
       "        ...,\n",
       "        [0.1240, 0.5719, 0.1252,  ..., 0.0340, 0.0432, 0.1434],\n",
       "        [0.1783, 0.5770, 0.3486,  ..., 0.0658, 0.0317, 0.2162],\n",
       "        [0.0741, 0.3467, 0.1679,  ..., 0.0286, 0.0853, 0.0655]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ids = img_name\n",
    "\n",
    "image_features = {img_id : features[0][i] for i, img_id in enumerate(img_ids)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image_ID:985982384 and features: tensor([0.1053, 0.9231, 0.3318,  ..., 0.0904, 0.1563, 0.1781])\n",
      "Image_ID:986127455 and features: tensor([0.2849, 0.4690, 0.5033,  ..., 0.1356, 0.2589, 0.3747])\n",
      "Image_ID:986440271 and features: tensor([0.1355, 0.1182, 0.3567,  ..., 0.0315, 0.0560, 0.1500])\n",
      "Image_ID:987442144 and features: tensor([0.2363, 0.1451, 1.1998,  ..., 0.1033, 0.2156, 0.1499])\n",
      "Image_ID:98756067 and features: tensor([0.1110, 0.3214, 0.0895,  ..., 0.0908, 0.1907, 0.2727])\n",
      "Image_ID:98756125 and features: tensor([0.1387, 0.2314, 0.1611,  ..., 0.0317, 0.0471, 0.1555])\n",
      "Image_ID:98773047 and features: tensor([0.2167, 0.4588, 0.1797,  ..., 0.0921, 0.2046, 0.1184])\n",
      "Image_ID:987907964 and features: tensor([0.1083, 0.0819, 0.2008,  ..., 0.3558, 0.2337, 0.1420])\n",
      "Image_ID:98817947 and features: tensor([0.1727, 0.4189, 0.7477,  ..., 0.1516, 0.2114, 0.2324])\n",
      "Image_ID:98885561 and features: tensor([0.2566, 0.6387, 0.5218,  ..., 0.0476, 0.0831, 0.1915])\n",
      "Image_ID:98944492 and features: tensor([0.1429, 0.4789, 0.6024,  ..., 0.0431, 0.1304, 0.2915])\n",
      "Image_ID:989754491 and features: tensor([0.1917, 0.5105, 0.4341,  ..., 0.0857, 0.1314, 0.2613])\n",
      "Image_ID:989851184 and features: tensor([0.1487, 0.1611, 0.7034,  ..., 0.0196, 0.1873, 0.1387])\n",
      "Image_ID:990890291 and features: tensor([0.1746, 0.4795, 0.5825,  ..., 0.1559, 0.1839, 0.0846])\n",
      "Image_ID:991459749 and features: tensor([0.1478, 0.3751, 0.5367,  ..., 0.0311, 0.1987, 0.1619])\n",
      "Image_ID:99171998 and features: tensor([0.1817, 0.3001, 0.7274,  ..., 0.0302, 0.1846, 0.2018])\n",
      "Image_ID:99458430 and features: tensor([0.0895, 0.3081, 0.2396,  ..., 0.1219, 0.2347, 0.1540])\n",
      "Image_ID:9950858 and features: tensor([0.2049, 0.2715, 0.2487,  ..., 0.0494, 0.3861, 0.1609])\n",
      "Image_ID:9950913 and features: tensor([0.1240, 0.5719, 0.1252,  ..., 0.0340, 0.0432, 0.1434])\n",
      "Image_ID:99679241 and features: tensor([0.1783, 0.5770, 0.3486,  ..., 0.0658, 0.0317, 0.2162])\n",
      "Image_ID:99804383 and features: tensor([0.0741, 0.3467, 0.1679,  ..., 0.0286, 0.0853, 0.0655])\n"
     ]
    }
   ],
   "source": [
    "for i,feat in image_features.items():\n",
    "    print(f'Image_ID:{i} and features: {feat}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORKING ON THE CAPTION DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = {}\n",
    "file = open(\"C:\\\\Python course\\\\Major\\\\result.txt\",\"r\")\n",
    "all_text = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('[\\n\\.]','',text)\n",
    "    text = re.sub(\"[^a-z]+\",\" \",text)\n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_dictionary = {}\n",
    "for text in all_text:\n",
    "    text = text.split(\"|\")\n",
    "    if text[0].endswith('.jpg'):\n",
    "        temp_list=[]\n",
    "        if text[0][:-4] not in content_dictionary:\n",
    "            clean_text = clean_string(text[-1]) \n",
    "            temp_list.append(clean_text)\n",
    "            content_dictionary[text[0][:-4]] = temp_list\n",
    "        else:\n",
    "            clean_text = clean_string(text[-1])\n",
    "            content_dictionary[text[0][:-4]].append(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_dictionary = {img_id:content for img_id,content in content_dictionary.items() if img_id in img_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'985982384': ['some women and men are sun tanning and watching the ocean waves on a bunch of rocks',\n",
       "  'two women relaxing while two men have a conversation on a rock',\n",
       "  'a group of sunbathers lies on the rocks on towels and blankets',\n",
       "  'men and women in swimsuits hangout on rocks above water',\n",
       "  'group of sunbathers laying on the rocks'],\n",
       " '986127455': ['man walking down the street is wearing a black suit and carrying a small white bag',\n",
       "  'a person with a bag walking in a big city',\n",
       "  'people walking a standing in a city park',\n",
       "  'a woman in a black suit is walking by',\n",
       "  'a person is walking with a white bag'],\n",
       " '986440271': ['a young woman in a red flowered dress and a multicolored umbrella is taking a picture of something and there is a large tree in the background',\n",
       "  'a woman in a red floral dress with cardigan takes a photo on a nature trail while holding a rainbow umbrella',\n",
       "  'a woman with a multicolored umbrella takes a picture on a road surrounded by trees',\n",
       "  'a woman with a rainbow umbrella sanding on a road with a handheld camera',\n",
       "  'a woman with a colorful umbrella is taking a picture'],\n",
       " '987442144': ['a young couple prepare a salad together in their kitchen',\n",
       "  'a man and a woman are making two bowls of salad together',\n",
       "  'a man in a striped shirt and a woman are making salads',\n",
       "  'a man and a woman are tossing salads',\n",
       "  'a man and a woman are making salads'],\n",
       " '98756067': ['two men are practicing karate in a room with white brick walls and is in front of some blacked out windows',\n",
       "  'two men practicing a form of martial arts in a wooden floored studio',\n",
       "  'one man violently defeating another man in a matrix style battle',\n",
       "  'two men in white robes and black belts are practicing karate',\n",
       "  'two people are displaying a form of martial arts'],\n",
       " '98756125': ['an asian man practices martial arts in a karate outfit as one hand raises above his head and another out stretches to the side',\n",
       "  'an older male with glasses and gray hair and mustache posing for a martial arts picture',\n",
       "  'an asian man in his karate uniform doing a karate stance',\n",
       "  'a man in a karate pose on a wooden floor',\n",
       "  'an older man is doing a karate pose'],\n",
       " '98773047': ['people sitting at and walking around out front of a sweets cafe',\n",
       "  'people are standing outside of the cafe about to go in',\n",
       "  'people outside of beard papa sweets cafe',\n",
       "  'a busy cafe in an outdoor mall is shown',\n",
       "  'people stand outside a shop at night'],\n",
       " '987907964': ['one brown and white dog chasing a black and white dog through the grass',\n",
       "  'two dogs are running through the grass near a house and trees',\n",
       "  'two cocker spaniels running through the grass',\n",
       "  'the two dogs are running through the grass',\n",
       "  'two dogs are running through a green yard'],\n",
       " '98817947': ['a smiling warehouse worker with a tattoo on his forearm gives the peace sign while surrounded by cardboard boxes',\n",
       "  'a factory worker takes a break from his day to pose for the camera',\n",
       "  'a man takes a quick break from working to pose of a picture',\n",
       "  'a large man in a factory is flashing the peace sign',\n",
       "  'burly warehouse worker giving the victory sign'],\n",
       " '98885561': ['a person is sliding down a slide with a coat jacket gloves and boots on',\n",
       "  'child sliding down an orange and blue slide in the winter',\n",
       "  'a boy in winter clothes slides down an orange slide',\n",
       "  'a child in snow gear sliding down a slide in winter',\n",
       "  'a child slides down an orange slide'],\n",
       " '98944492': ['a man walks on the street with a snow shovel during a snowstorm',\n",
       "  'person with shovel walks through snowstorm in front of cafe',\n",
       "  'a person with red gloves carries a shovel through the snow',\n",
       "  'a person is carrying a shovel walking down a snowy street',\n",
       "  'someone is walking through a snowstorm carrying a shovel'],\n",
       " '989754491': ['a red haired girl making a peace sign is wearing neon green glasses and floaties and playing in the pool with other kids',\n",
       "  'a young girl with goggles and floaties poses for the camera as she plays in a pool',\n",
       "  'a redheaded girl offers the peace sign as she swims in the pool with floaties',\n",
       "  'a girl in a pool wearing goggles and surrounded by other children',\n",
       "  'a girl in green goggles in a pool with three other children'],\n",
       " '989851184': ['a black dog has a dumbbell in his mouth looking at the person wearing blue',\n",
       "  'a black dog holding a weight in its mouth stands next to a person',\n",
       "  'the black dog has a toy in its mouth and a person stands nearby',\n",
       "  'a black dog holds a small white dumbbell in its mouth',\n",
       "  'a black dog has a dumbbell in his mouth'],\n",
       " '990890291': ['asian man in orange hat is popping a wheelie on his bike',\n",
       "  'a man does a wheelie on his bicycle on the sidewalk',\n",
       "  'a man on a bicycle is on only the back wheel',\n",
       "  'a man is doing a wheelie on a mountain bike',\n",
       "  'man on a bicycle riding on only one wheel'],\n",
       " '991459749': ['an obese man and two average sized men sit on a bench with their heads as far back as they will go',\n",
       "  'three men one with his shoes off are asleep on a bench in the park',\n",
       "  'three men taking an afternoon nap',\n",
       "  'three men relaxing on a bench',\n",
       "  'three men sleep on a bench'],\n",
       " '99171998': ['a group of people sit in the snow overlooking a mountain scene',\n",
       "  'five people are sitting together in the snow',\n",
       "  'a group of people sit atop a snowy mountain',\n",
       "  'a group is sitting around a snowy crevasse',\n",
       "  'five children getting ready to sled'],\n",
       " '99458430': ['people standing around laughing at a woman sitting on the ground covered in cake',\n",
       "  'a woman wearing high heels falls backwards as onlookers laugh',\n",
       "  'a woman on the floor and people standing around her',\n",
       "  'woman wearing high heels falls on a cake',\n",
       "  'a woman on the floor covered in cake'],\n",
       " '9950858': ['one police officer standing on the street along with three police officers on horseback',\n",
       "  'a group of people on horses ride down a city street behind others who are walking',\n",
       "  'three mounted police stand in the middle of a street',\n",
       "  'a troupe of police officers atop horses in the city',\n",
       "  'police on horseback at an outside protest'],\n",
       " '9950913': ['a group of people are wearing signs that say on strike while someone is speaking at a booth with the presidential seal',\n",
       "  'a strike is currently going on and there are lots of people',\n",
       "  'a person speaks at a protest on a college campus',\n",
       "  'a woman is speaking at a podium outdoors',\n",
       "  'members of a strike at yale university'],\n",
       " '99679241': ['a gray bird stands majestically on a beach while waves roll in',\n",
       "  'a white crane stands tall as it looks out upon the ocean',\n",
       "  'a tall bird is standing on the sand beside the ocean',\n",
       "  'a large bird stands in the water on the beach',\n",
       "  'a water bird standing at the ocean s edge'],\n",
       " '99804383': ['an older busker in glasses plays an eastern string instrument for a young boy in a striped shirt',\n",
       "  'this is a man in front of a store performing with a little boy standing with a dollar in his hand',\n",
       "  'a older asian man is playing an instrument in front of a young boy on the street',\n",
       "  'an elderly man sits outside a storefront accompanied by a young boy with a cart',\n",
       "  'an elderly gentleman playing a musical instrument on the sidewalk for money']}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_word = []\n",
    "for i,word in content_dictionary.items():\n",
    "    for w in word:\n",
    "        for j in w.split():\n",
    "            total_word.append(j)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'some': 2, 'women': 3, 'and': 30, 'men': 11, 'are': 17, 'sun': 1, 'tanning': 1, 'watching': 1, 'the': 45, 'ocean': 4, 'waves': 2, 'on': 41, 'a': 166, 'bunch': 1, 'of': 23, 'rocks': 4, 'two': 12, 'relaxing': 2, 'while': 5, 'have': 1, 'conversation': 1, 'rock': 1, 'group': 7, 'sunbathers': 2, 'lies': 1, 'towels': 1, 'blankets': 1, 'in': 51, 'swimsuits': 1, 'hangout': 1, 'above': 2, 'water': 3, 'laying': 1, 'man': 23, 'walking': 9, 'down': 8, 'street': 7, 'is': 24, 'wearing': 7, 'black': 9, 'suit': 2, 'carrying': 3, 'small': 2, 'white': 8, 'bag': 3, 'person': 10, 'with': 25, 'big': 1, 'city': 4, 'people': 14, 'standing': 8, 'park': 2, 'woman': 16, 'by': 5, 'young': 6, 'red': 4, 'flowered': 1, 'dress': 2, 'multicolored': 2, 'umbrella': 5, 'taking': 3, 'picture': 5, 'something': 1, 'there': 2, 'large': 3, 'tree': 1, 'background': 1, 'floral': 1, 'cardigan': 1, 'takes': 4, 'photo': 1, 'nature': 1, 'trail': 1, 'holding': 2, 'rainbow': 2, 'road': 2, 'surrounded': 3, 'trees': 2, 'sanding': 1, 'handheld': 1, 'camera': 3, 'colorful': 1, 'couple': 1, 'prepare': 1, 'salad': 2, 'together': 3, 'their': 2, 'kitchen': 1, 'making': 4, 'bowls': 1, 'striped': 2, 'shirt': 2, 'salads': 3, 'tossing': 1, 'practicing': 3, 'karate': 7, 'room': 1, 'brick': 1, 'walls': 1, 'front': 5, 'blacked': 1, 'out': 4, 'windows': 1, 'form': 2, 'martial': 4, 'arts': 4, 'wooden': 2, 'floored': 1, 'studio': 1, 'one': 6, 'violently': 1, 'defeating': 1, 'another': 2, 'matrix': 1, 'style': 1, 'battle': 1, 'robes': 1, 'belts': 1, 'displaying': 1, 'an': 16, 'asian': 4, 'practices': 1, 'outfit': 1, 'as': 7, 'hand': 2, 'raises': 1, 'his': 10, 'head': 1, 'stretches': 1, 'to': 6, 'side': 1, 'older': 4, 'male': 1, 'glasses': 3, 'gray': 2, 'hair': 1, 'mustache': 1, 'posing': 1, 'for': 5, 'uniform': 1, 'doing': 3, 'stance': 1, 'pose': 4, 'floor': 3, 'sitting': 4, 'at': 10, 'around': 4, 'sweets': 2, 'cafe': 5, 'outside': 5, 'about': 1, 'go': 2, 'beard': 1, 'papa': 1, 'busy': 1, 'outdoor': 1, 'mall': 1, 'shown': 1, 'stand': 2, 'shop': 1, 'night': 1, 'brown': 1, 'dog': 7, 'chasing': 1, 'through': 8, 'grass': 4, 'dogs': 3, 'running': 4, 'near': 1, 'house': 1, 'cocker': 1, 'spaniels': 1, 'green': 3, 'yard': 1, 'smiling': 1, 'warehouse': 2, 'worker': 3, 'tattoo': 1, 'forearm': 1, 'gives': 1, 'peace': 4, 'sign': 5, 'cardboard': 1, 'boxes': 1, 'factory': 2, 'break': 2, 'from': 2, 'day': 1, 'quick': 1, 'working': 1, 'flashing': 1, 'burly': 1, 'giving': 1, 'victory': 1, 'sliding': 3, 'slide': 5, 'coat': 1, 'jacket': 1, 'gloves': 2, 'boots': 1, 'child': 3, 'orange': 4, 'blue': 2, 'winter': 3, 'boy': 5, 'clothes': 1, 'slides': 2, 'snow': 5, 'gear': 1, 'walks': 2, 'shovel': 5, 'during': 1, 'snowstorm': 3, 'carries': 1, 'snowy': 3, 'someone': 2, 'haired': 1, 'girl': 5, 'neon': 1, 'floaties': 3, 'playing': 3, 'pool': 5, 'other': 3, 'kids': 1, 'goggles': 3, 'poses': 1, 'she': 2, 'plays': 2, 'redheaded': 1, 'offers': 1, 'swims': 1, 'children': 3, 'three': 7, 'has': 3, 'dumbbell': 3, 'mouth': 5, 'looking': 1, 'weight': 1, 'its': 3, 'stands': 5, 'next': 1, 'toy': 1, 'nearby': 1, 'holds': 1, 'hat': 1, 'popping': 1, 'wheelie': 3, 'bike': 2, 'does': 1, 'bicycle': 3, 'sidewalk': 2, 'only': 2, 'back': 2, 'wheel': 2, 'mountain': 3, 'riding': 1, 'obese': 1, 'average': 1, 'sized': 1, 'sit': 3, 'bench': 4, 'heads': 1, 'far': 1, 'they': 1, 'will': 1, 'shoes': 1, 'off': 1, 'asleep': 1, 'afternoon': 1, 'nap': 1, 'sleep': 1, 'overlooking': 1, 'scene': 1, 'five': 2, 'atop': 2, 'crevasse': 1, 'getting': 1, 'ready': 1, 'sled': 1, 'laughing': 1, 'ground': 1, 'covered': 2, 'cake': 3, 'high': 2, 'heels': 2, 'falls': 2, 'backwards': 1, 'onlookers': 1, 'laugh': 1, 'her': 1, 'police': 5, 'officer': 1, 'along': 1, 'officers': 2, 'horseback': 2, 'horses': 2, 'ride': 1, 'behind': 1, 'others': 1, 'who': 1, 'mounted': 1, 'middle': 1, 'troupe': 1, 'protest': 2, 'signs': 1, 'that': 1, 'say': 1, 'strike': 3, 'speaking': 2, 'booth': 1, 'presidential': 1, 'seal': 1, 'currently': 1, 'going': 1, 'lots': 1, 'speaks': 1, 'college': 1, 'campus': 1, 'podium': 1, 'outdoors': 1, 'members': 1, 'yale': 1, 'university': 1, 'bird': 4, 'majestically': 1, 'beach': 2, 'roll': 1, 'crane': 1, 'tall': 2, 'it': 1, 'looks': 1, 'upon': 1, 'sand': 1, 'beside': 1, 's': 1, 'edge': 1, 'busker': 1, 'eastern': 1, 'string': 1, 'instrument': 3, 'this': 1, 'store': 1, 'performing': 1, 'little': 1, 'dollar': 1, 'elderly': 2, 'sits': 1, 'storefront': 1, 'accompanied': 1, 'cart': 1, 'gentleman': 1, 'musical': 1, 'money': 1}\n"
     ]
    }
   ],
   "source": [
    "frequency_data = dict(collections.Counter(total_word))\n",
    "print(frequency_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Finally we have 2 dictionary \\n    image_features --> this has your image features in 2048 vector\\n    content_dictionary ---> this has your image caption data\\n'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    Finally we have 2 dictionary \n",
    "    image_features --> this has your image features in 2048 vector\n",
    "    content_dictionary ---> this has your image caption data\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TIME TO BUILD A LSTM FOR CAPTION GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import Dense,LSTM\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
